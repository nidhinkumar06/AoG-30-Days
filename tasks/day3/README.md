<div align="center">
  <h1>Actions on Google - Day 3</h1>
  <p>How to build actions for smart displays</p>
</div>

# Overview
* Voice experience is the foundation
* Use dialogue to guide the user
* Use rich response to augment the voice experience
* Use Interactive canvas for games

<div align="center">
   <img src="../../assets/day3/tools.png" alt="aog-tools" height="300">
</div>

Different set of surface where Google Asistant works

<div align="center">
   <img src="../../assets/day3/devicecheck.png" alt="aog-surfaces" height="300">
</div>

Grouping of surfaces

<div align="center">
   <img src="../../assets/day3/groupingofsurface.png" alt="aog-grouping" height="300">
</div>


# Voice experience is the foundation

Let's have a look at the pet adoption flow

<div align="center">
   <img src="../../assets/day3/petadoption-gameplay.png" alt="petadoption-flow" height="300">
</div>

If you see the below image on how the default welcome intent was called at first

<div align="center">
   <img src="../../assets/day3/before.png" alt="before" height="300">
</div>

If you see the response you could see something as `we` which denotes whom ? as well as at the bottom `pls tell me your name` which no user will give at the first pace itself.

Let's see how it is changed

<div align="center">
   <img src="../../assets/day3/after.png" alt="after" height="300">
</div>

Here instead of directly asking the user name we have asking the user whether the user is interested to adopt a pet or not?

# Use Dialogue to guide the user

If you look at the below dialogue you could see we have asked everthing in a single stretch

<div align="center">
   <img src="../../assets/day3/before-dialogue.png" alt="after" height="300">
</div>

If you see the below one you could see we have done 2 things we have asked whether the user is able to feed the hamster as well as to exercise the hamster


<div align="center">
   <img src="../../assets/day3/after-dialogue.png" alt="after" height="300">
</div>

Creating a complete voice experience

<div align="center">
   <img src="../../assets/day3/complete-voice-experience.png" alt="after" height="300">
</div>

# Use rich response to augment the voice experience

Will see some the rich response which can be added to the action. If you see the below flows

<div align="center">
   <img src="../../assets/day3/flow2.png" alt="after" height="300">
</div>

<div align="center">
   <img src="../../assets/day3/flow3.png" alt="after" height="300">
</div>

We would use some rich response to showcase the users what they can feed the hamster and which exercise they can do for their hamster using some of the responses like

* Carousel
* Suggestion Chips
* List
* Media response


# Use Interactive canvas for games

Using interactive canvas we can create a rich set of animations, displays using HTML, CSS and JavaScript

<div align="center">
   <img src="../../assets/day3/experience-enchrichment.png" alt="after" height="300">
</div>

The interactive canvas is available only for *games category


## What about mobile ?

Suppose if the user is invoked your action in a smart speaker and that particular action has some images to be displayed out. It can be done if the user has any screen output like the below image

<div align="center">
   <img src="../../assets/day3/displayingpicture.png" alt="display" height="300">
</div>

## Tools

* Use Storyboard (Using a pen and a paper create stories)
* UI Toolkit (How the image will be shown in smaller mobile screens and bigger screens)
* Actions simulator (Use actions simulator to test your action in different surfaces)

## Resource Links

<div align="center">
   <img src="../../assets/day3/resources.png" alt="resources" height="300">
</div>

<div align="center">
   <img src="../../assets/day3/resources2.png" alt="resources2" height="300">
</div>

